== [[ShuffleMapTask]] ShuffleMapTask

`ShuffleMapTask` divides the elements of an RDD into multiple buckets (based on a partitioner specified in link:spark-rdd-ShuffleDependency.adoc[ShuffleDependency]).

=== [[runTask]] `runTask` Method

[source, scala]
----
runTask(context: TaskContext): MapStatus
----

NOTE: `runTask` is a part of link:spark-taskscheduler-tasks.adoc#contract[Task contract] to...FIXME

`runTask` computes a <<MapStatus, MapStatus>>.

Internally, `runTask`...FIXME

=== [[MapStatus]] MapStatus

A `MapStatus` is the result returned by a link:spark-taskscheduler-ShuffleMapTask.adoc[ShuffleMapTask] to link:spark-dagscheduler.adoc[DAGScheduler] that includes:

* the *location* where ShuffleMapTask ran (as `def location: BlockManagerId`)
* an *estimated size for the reduce block*, in bytes (as `def getSizeForBlock(reduceId: Int): Long`).

There are two types of MapStatus:

* *CompressedMapStatus* that compresses the estimated map output size to 8 bits (`Byte`) for efficient reporting.
* *HighlyCompressedMapStatus* that stores the average size of non-empty blocks, and a compressed bitmap for tracking which blocks are empty.

When the number of blocks (the size of `uncompressedSizes`) is greater than *2000*, HighlyCompressedMapStatus is chosen.

CAUTION: FIXME What exactly is 2000? Is this the number of tasks in a job?
